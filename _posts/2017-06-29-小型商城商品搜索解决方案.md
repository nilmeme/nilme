---
title: 小型商城商品搜索解决方案
date: 2017-06-29 17:03:25
category:
toc: true
classes: narrow
---

在开发中可能因为条件不允许，无法使用一些像 **Lucene** 、 **Solr** 这样的大型搜索引擎。

所以就需要找一些可以直接集成到原系统的解决方案。然后就有了现在的解决方案：**thulac4j** + Mysql5.7数据库全文索引

<!--more-->

### thulac4j

thulac4j是THULAC的高效Java 8实现，具有分词速度快、准、强的特点；支持
1. 自定义词典
2. 繁体转简体
3. 停用词过滤

thulac4j支持两种分词模式：

1. SegOnly模式，只分词没有词性标注；
2. SegPos模式，分词兼有词性标注。

```java
// SegOnly mode
String sentence = "滔滔的流水，向着波士顿湾无声逝去";
SegOnly seg = new SegOnly("models/seg_only.bin");
System.out.println(seg.segment(sentence));
// [滔滔, 的, 流水, ，, 向着, 波士顿湾, 无声, 逝去]

// SegPos mode
SegPos pos = new SegPos("models/seg_pos.bin");
System.out.println(pos.segment(sentence));
// [滔滔/a, 的/u, 流水/n, ，/w, 向着/p, 波士顿湾/ns, 无声/v, 逝去/v]
```

模型数据较大，没有放在jar包与源码。训练模型下载及更多使用说明，请参看[Getting Started](https://github.com/yizhiru/thulac4j/wiki).

同类的还有其他的中文分词技术，有时间都可以试试。选一个最合适自己的。

### MySQL中文全文检索

一、概述

MySQL全文检索是利用查询关键字和查询列内容之间的相关度进行检索，可以利用全文索引来提高匹配的速度。

二、语法

```sql
MATCH (col1,col2,...) AGAINST (expr [search_modifier])
search_modifier: { IN BOOLEAN MODE | WITH QUERY EXPANSION }
```

例如：

```sql
SELECT * FROM tab_name WHERE MATCH ('列名1,列名2...列名n') AGAINST('词1 词2 词3 ... 词m');
search_modifier: { IN BOOLEAN MODE | WITH QUERY EXPANSION }
```

即：MATCH 相当于要匹配的列，而 AGAINST 就是要找的内容。  
这里的table需要是MyISAM类型的表，col1、col2 必须是char、varchar或text类型，在查询之前需要在 col1 和 col2 上分别建立全文索引(FULLTEXT索引)。

三、检索方式
1. 自然语言检索： IN NATURAL LANGUAGE MODE

2. 布尔检索： IN BOOLEAN MODE
剔除一半匹配行以上都有的词，譬如说，每个行都有this这个字的话，那用this去查时，会找不到任何结果，这在记录条数特别多时很有用，
原因是数据库认为把所有行都找出来是没有意义的，这时，this几乎被当作是stopword(中断词)；但是若只有两行记录时，是啥鬼也查不出来的，
因为每个字都出现50%（或以上），要避免这种状况，请用IN BOOLEAN MODE。

● IN BOOLEAN MODE的特色：

· 不剔除50%以上符合的row。
· 不自动以相关性反向排序。
· 可以对没有FULLTEXT index的字段进行搜寻，但会非常慢。
· 限制最长与最短的字符串。
· 套用Stopwords。

● 搜索语法规则：
``+``   一定要有(不含有该关键词的数据条均被忽略)。
``-``   不可以有(排除指定关键词，含有该关键词的均被忽略)。
``>``   提高该条匹配数据的权重值。
``<``   降低该条匹配数据的权重值。
~   将其相关性由正转负，表示拥有该字会降低相关性(但不像 - 将之排除)，只是排在较后面权重值降低。
``*``   万用字，不像其他语法放在前面，这个要接在字符串后面。
``""``  用双引号将一段句子包起来表示要完全相符，不可拆字。

```sql
SELECT * FROM articles WHERE MATCH (title,content) AGAINST ('+apple -banana' IN BOOLEAN MODE);
```

+ 表示AND，即必须包含。- 表示NOT，即必须不包含。即：返回记录必需包含 apple，且不能包含 banner。

```sql
SELECT * FROM articles WHERE MATCH (title,content) AGAINST ('apple banana' IN BOOLEAN MODE);
```

apple和banana之间是空格，空格表示OR。即：返回记录至少包含apple、banana中的一个。
```sql
SELECT * FROM articles WHERE MATCH (title,content) AGAINST ('+apple banana' IN BOOLEAN MODE);
```
返回记录必须包含apple，同时banana可包含也可不包含，若包含的话会获得更高的权重。
```sql
SELECT * FROM articles WHERE MATCH (title,content) AGAINST ('+apple ~banana' IN BOOLEAN MODE);
```
~ 是我们熟悉的异或运算符。返回记录必须包含apple，若也包含了banana会降低权重。
但是它没有 +apple -banana 严格，因为后者如果包含banana压根就不返回。
```sql
SELECT * FROM articles WHERE MATCH (title,content) AGAINST ('+apple +(>banana <orange)' IN BOOLEAN MODE);
```
返回必须同时包含 **apple banana** 或者必须同时包含 **apple orange** 的记录。
若同时包含 **apple banana** 和 **apple orange** 的记录，则 **apple banana** 的权重高于 **apple orange** 的权重。

3. 查询扩展检索： WITH QUERY EXPANSION


四、MySQL全文检索的条件限制
1、在MySQL5.6以下，只有MyISAM表支持全文检索。在MySQL5.6以上Innodb引擎表也提供支持全文检索。
2、相应字段建立FULLTEXT索引


五、与全文检索相关的系统变量：
ft_min_word_len = 全文检索的最小许可字符(默认4，通过 SHOW VARIABLES LIKE 'ft_min_word_len' 可查看)，
中文通常是两个字就是一个词，所以做中文的话需要修改这个值为2最好。


六、总结事项
1. 预设搜寻是不分大小写，若要分大小写，columne 的 character set要从utf8改成utf8_bin。

2. 预设 MATCH...AGAINST 是以相关性排序，由高到低。

3. MATCH(title, content)里的字段必须和FULLTEXT(title, content)里的字段一模一样。
如果只要单查title或content一个字段，那得另外再建一个 FULLTEXT(title) 或 FULLTEXT(content)，也因为如此，MATCH()的字段一定不能跨table，但是另外两种搜寻方式好像可以。

4. MySQL不支持中文全文索引，原因很简单：与英文不同，中文的文字是连着一起写的，中间没有MySQL能找到分词的地方，截至目前MySQL5.6版本是如此，但是有变通的办法，就是将整句的中文分词，并按urlencode、区位码、base64、拼音等进行编码使之以“字母+数字”的方式存储于数据库中。


### InnoDB全文索引：N-gram Parser

InnoDB默认的全文索引parser非常合适于Latin，因为Latin是通过空格来分词的。但对于像中文，日文和韩文来说，没有这样的分隔符。一个词可以由多个字来组成，所以我们需要用不同的方式来处理。在MySQL 5.7.6中我们能使用一个新的全文索引插件来处理它们：**n-gram parser** .


### 什么是N-gram？

在全文索引中，n-gram就是一段文字里面连续的n个字的序列。例如，用n-gram来对”信息系统”来进行分词，得到的结果如下：

```sql
N=1 : '信', '息', '系', '统';
N=2 : '信息', '息系', '系统';
N=3 : '信息系', '息系统';
N=4 : '信息系统';
```

### 如何在InnoDB中使用N-gram Parser？

**N-gram parser** 是默认加载到MySQL中并可以直接使用的。我们只需要在DDL中创建全文索引时使用 **TH PARSER ngram** 。比如，下面的SQL语句在MySQL 5.7.6及更高版本上可以运行。

```sql
mysql > CREATE TABLE articles
(
        FTS_DOC_ID BIGINT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
        title VARCHAR(100),
        FULLTEXT INDEX ngram_idx(title) WITH PARSER ngram
) Engine=InnoDB CHARACTER SET utf8mb4;
Query OK, 0 rows affected (0.06 sec)
mysql> # ALTER TABLE articles ADD FULLTEXT INDEX ngram_idx(title) WITH PARSER ngram;
mysql> # CREATE FULLTEXT INDEX ngram_idx ON articles(title) WITH PARSER ngram;
```

我们引入了一个新的全局变量叫 **ngram_token_size** 。由它来决定 **n-gram** 中n的大小，也就是词的大小。它的默认值是2，这个时候，我们使用的是 **bigram** 。它的合法的取值范围是1到10。现在，我们很自然会想到一个问题：实际应用中应该如何设置 **ngram_token_size** 值的大小呢？当然，我们推荐使用2。但是你也可以通过如下这个简单的规则来可以选择任何合法的值：设置到你希望能查询到的最小的词的大小。如果你想查询到单个字，那么我们需要设置为1。 **ngram_token_size** 的值设置的越小，全文索引占用的空间也越小。一般来说，查询正好等于 **ngram_token_size** 的词，速度会更快，但是查询比它更长的词或短语，则会变慢。

### N-gram分词处理

N-gram parser和系统默认的全文索引parser有如下不同点：

1. 词大小检查：因为有了ngram_token_size，所以innodb_ft_min_token_size和innodb_ft_max_token_size将不适用于n-gram。

2. 我们可以通过查询 **INFORMATION_SCHEMA.INNODB_FT_INDEX_CACHE** 和 **INFORMATION_SCHEMA.INNODB_FT_TABLE_TABLE** 来查询哪些词在全文索引里面。这是一个非常有用的调试工具。如果我们发现一个包含某个词的文档，没有如我们所期望的那样出现在查询结果中，那么这个词可能是因为某些原因不在全文索引里面。比如，它含有 **stopword** ，或者它的大小小于 **ngram_token_size** 等等。

### 总结

在结合了 **thulac4j** + Mysql5.7数据库全文索引之后，我们先使用 **thulac4j** 对用户的关键词进行分词，之后在需要搜索的字段上加上全文索引，这样就可以满足我们的需求了。这里唯一的不足就是数据库必须使用5.7.6以上的版本。
